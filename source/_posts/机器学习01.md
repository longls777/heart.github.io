---
title: 机器学习-模型评估与选择
tags: machine learning
categories: 《机器学习》笔记
date: 2022-07-11 12:27:30
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/123123131.webp
math: true
---



## 模型评估与选择

### 评估方法

#### 留出法

hold-out，直接将数据集划分为两个互斥的集合，其中一个作为训练集，另一个作为测试集，划分要尽可能保证数据分布的一致性，如使用分层采样(stratified sampling)，在分类任务中保证样本类别比例相似。

使用留出法，一般要采用若干次随即划分、重复进行实验评估后取平均值作为评估结果。

#### 交叉验证法

将数据集划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，然后每次用k-1个子集作为训练集，剩下的那个作为测试集，这样可以进行k次训练和测试，最终返回的是k次测试结果的均值。也称为“k折交叉验证”(k-fold cross validation)，由于划分方式的不同，通常使用不同的划分重复p次，成为"p次k折交叉验证"

设数据集中共有m个样本，当k=m时，就得到了交叉验证法的一个特例:留一法(Leave-One-Out)，留一法不受样本划分方式的影响，但是当训练集较大时，需要训练很多的模型，开销很大。

#### 自助法

bootstrapping以自助采样法(bootstrap sampling)为基础，使用$D'$作为训练集，$D/D'$作为测试集，这样，仍有约1/3的测试样本未在训练集中出现过，这样的测试结果称为"包外估计"(out-of-bag estimate)

> 自助采样法：给定包含m个样本的数据集$D$，采样生成数据集$D'$，采样方法是：每次随机复制一个$D$中的样本到$D'$，重复m次，这样得到的$D'$大小同样为m，很明显$D$中有些样本会在$D'$中多次出现，而有些则没有被采样到，其概率为
> $$
> \lim_{m\to\infty}(1-\frac{1}{m})^m=\frac{1}{e}\approx0.368
> $$
> 

自助法在数据集较小、难以有效划分训练/测试集时很有用，但是产生的数据集改变了初始数据集的分布，这会引入估计偏差，所以在初始数据量足够时，留出法和交叉验证法更常用。

### 训练集、验证集和测试集

- 训练集：用于模型训练
- 验证集：基于验证集上的性能来进行模型选择和调参
- 测试集：用于评估不同算法的泛化能力

### 性能度量

#### 错误率和精度

常用于分类任务

- 错误率：分类错误的样本数占样本总数的比例
- 精度：分类正确的样本数占样本总数的比例

对于数据集$D$，错误率为：

![image-20220711134646640](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711134646640.png)

精度为：

![image-20220711134718114](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711134718114.png)

#### 查准率、查全率与F1

查准率precision 查全率recall

对于二分类问题：

![image-20220711135010500](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135010500.png)

![image-20220711135021750](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135021750.png)

![image-20220711135324446](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135324446.png)

平衡点(Break-Event Point, BEP)是查准率=查全率时的取值

![image-20220711135519394](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135519394.png)

F1更一般的形式为：

![image-20220711135627281](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135627281.png)

$\beta$表示了查全率P对查准率R的相对重要性，$\beta > 1$时查全率R更重要，$\beta < 1$时查准率P更重要

当有多个二分类混淆矩阵时，有两种做法：

![image-20220711135938423](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135938423.png)

![image-20220711135953185](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711135953185.png)

![image-20220711140002321](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711140002321.png)

#### ROC与AUC

ROC全称是”受试者工作特征“(Receiver Operating Characteristic)

ROC曲线纵轴为”真正例率“(True Positive Rate, TPR)，横轴为"假正例率"(False Positive Rate, FPR)

![image-20220711140451414](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711140451414.png)

![image-20220711140644229](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711140644229.png)

对角线对应”随机预测“模型，（0，1）坐标对应于分类完全准确

AUC(Area Under ROC Curve)是ROC曲线下的面积，可用来比较分类器的性能

#### 代价敏感错误率与代价曲线

![image-20220711141709339](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711141709339.png)

![image-20220711141814617](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711141814617.png)

![image-20220711141925154](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711141925154.png)

![image-20220711141933528](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711141933528.png)

### 偏差-方差分解

![image-20220711163816321](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711163816321.png)

泛化误差可分解为偏差、方差与噪声之和

- 偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力
- 方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响
- 噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界

![image-20220711164959677](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20220711164959677.png)